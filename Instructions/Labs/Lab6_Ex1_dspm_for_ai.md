---
lab:
  title: 演習 1 - AI 環境でデータを保護する
  module: Module 6 - Protect data in AI environments
---

## WWL テナント - 使用条件

講師が指導するトレーニング配信の一環としてテナントを提供されている場合は、講師が指導するトレーニングでハンズオンラボをサポートする目的でテナントを利用できることに注意してください。

テナントを共有したり、ハンズオンラボ以外の目的で使用したりしないでください。 このコースで使われるテナントは試用版テナントであり、クラスが終了し、拡張機能の対象となっていない場合は、使用したりアクセスしたりすることはできません。

テナントを有料サブスクリプションに変換することはできません。 このコースの一環として取得したテナントは Microsoft Corporation の財産のままであり、当社はいつでもアクセス権とリポジトリを取得する権利を留保します。

# ラボ 6 - 演習 1 - AI 環境でデータを保護する

あなたは、Contoso Ltd の情報セキュリティ管理者である Joni Sherman です。Microsoft Copilot などの AI ツールが毎日のワークフローに統合されるにつれて、チームは機密データに関する保護を評価して改善するように求められました。 このラボでは、Microsoft Purview の AI 用 DSPM を使用し、ポリシーの適用、リスク検出、露出評価を通じて AI ツールとのデータのやり取りをセキュリティで保護する方法について説明します。

**タスク**:

1. AI 用 DSPM を使用して生成 AI サイトの DLP ポリシーを作成する
1. リスクの高い AI の相互作用を検出するインサイダー リスク ポリシーを作成する
1. AI アプリでの非倫理的な動作を検出する
1. データ評価を実行してラベル付けされていないコンテンツを検出する

## タスク 1 - AI 用 DSPM を使用して生成 AI サイトの DLP ポリシーを作成する

AI アシスタントによるデータ損失のリスクを軽減するには、まず、データ セキュリティの強化に関する推奨事項を使用して DLP ポリシーを作成します。 このポリシーでは、適応型保護を使用して、ChatGPT、Copilot in Edge、Chrome、Firefox などの AI ツールへの機密データの貼り付けまたはアップロードを制限します。

1. **SC-401-cl1\admin** アカウントで Client 1 VM (SC-401-CL1) に ログインします。

1. **Microsoft Edge** で **`https://purview.microsoft.com`** に移動し、**Joni Sherman** (`JoniS@WWLxZZZZZZ.onmicrosoft.com`) としてサインインします (この ZZZZZZ は、ラボ ホスティング プロバイダーから提供された自分専用のテナント プレフィックスです)。 ユーザー アカウントのパスワードは、ラボ ホスティング プロバイダーから提供されます。

1. Microsoft Purview で、**[ソリューション]**、**[AI 用 DSPM]**、**[推奨事項]** の順に選択して AI 用 DSPM に移動します。

1. 推奨事項にある **[データセキュリティを強化する]** を選択します。

1. **[AI のデータ セキュリティ]** ポップアップ ページで概要を確認し、**[ポリシーを作成]** を選択します。 これにより、生成 AI サイトを対象とする事前構成済みの DLP ポリシーが作成されます。

1. ポリシーが作成されたら、**ポリシーが表示**されます。

1. **[ポリシーの詳細]** セクションで、**[ソリューションでポリシーを編集]** を選択し、Microsoft Purview で **[データ損失防止]** ソリューションを開きます。

1. **[ポリシー]** ページで、**AI 用 DSPM - AI サイトからの機密情報のブロック** ポリシーを見つけて選択します。

1. ポップアップで、**[シミュレーションの表示]** を選択します。

1. シミュレーション ダッシュボードで、**[ポリシーの編集]** を選択します。

1. **[このポリシーの適用先を選択します]** ページが表示されるまで、**[次へ]** を選択します。 ポリシーのスコープが**デバイス**であることを確認します。

1. [**次へ**] を選択します。

1. **[詳細な DLP ルールのカスタマイズ]** ページで、**[Block with override for elevated risk users]** の横にある鉛筆アイコンを選択してルールを表示します。

1. AI 用 DSPM で作成されたルールの構成を確認します。
   - **[条件]** で、含まれる機密情報の種類と、高いリスクに基づいて**適応型保護**がルールによって使用されることに注意してください。
   - **[操作]** での [アップロード] アクティビティと [貼り付け] アクティビティの両方で、**[機密性の高いサービス ドメイン グループの制限]** の横にある **[編集]** を選択します。
   - サービス ドメイン グループの構成で、**[生成 AI Web サイト]** が **[オーバーライドによるブロック]** に設定されていることを確認します。

1. **[キャンセル]** を選択して、ルール エディターを変更せずに終了します。

1. **[詳細な DLP ルールのカスタマイズ]** ページに戻り、**[次へ]** を選択します。

1. **[ポリシー モード]** ページで、**[シミュレーションから 15 以内に編集されなかった場合はポリシーをオンにします]** を選択し、**[次へ]** を選択します。

1. **[確認と終了]** ページで、**[送信]** を選択して、**[完了]** を選択します。

リスクの高いユーザーが生成 AI サイトで機密データを共有できないようにするポリシーを作成し、AI 用 DSPM で設定したポリシー構成を確認しました。

## タスク 2 - 危険な AI の相互作用を検出するインサイダー リスク ポリシーを作成する

次に、Copilot で危険なプロンプトの動作を検出するのに役立つポリシーを作成します。

1. Microsoft Purview で、**[ソリューション]**、**[AI 用 DSPM]**、**[推奨事項]** の順に選択して **[AI 用 DSPM]** に移動します。

1. **[AI アプリ内での危険なやり取りを検出する (プレビュー)]** という推奨事項を選択します。

1. **[AI アプリ内での危険なやり取りを検出する (プレビュー)]** ポップアップ ページで、概要を確認し、**[ポリシーを作成]** を選択します。

1. ポリシーが作成されたら、**[ポリシーの表示]** を選択します。

1. **[ポリシーの詳細]** セクションで、**[ソリューションでポリシーを編集]** を選択し、Microsoft Purview の **[インサイダー リスク管理]** エリアを開きます。

1. **[ポリシー]** ページで、**DSPM for AI - Detect risky AI usage** ポリシーを見つけて選択します。

1. ポップアップで、**[ポリシーの編集]** を選択して、ポリシー全体の構成を確認します。

1. **[ポリシー テンプレートの選択]** ページで、ポリシーが **"危険性のある AI の使用"** テンプレートを使用していることを確認します。

1. **[このポリシーのトリガー イベントの選択] ページ**に到達するまで **[次へ]** を選択します。
トリガー イベントが、危険な AI アクティビティの前後に発生する可能性のあるオフボード関連のリスクを通知する、**[ユーザー アカウントが Microsoft Entra ID から削除されました]** であることを確認します。

1. [**次へ**] を選択します。

1. **[指標]** ページで、インジケーター カテゴリを展開して、選択されている次のようなシグナルを確認します。

   - 生成的な AI Web サイトを参照しました
   - Copilot から機密性の高い応答を受信しています
   - Copilot で危険なプロンプトを入力しています

1. **[確認と完了]** ページに到達するまで **[次へ]** を選択し、**[キャンセル]** を選択して、変更を加えずにエディターを終了します。

プロンプトや応答など、危険な AI 対話を検出するポリシーを作成して、危険なユーザー行動の初期の兆候を特定できるようになりました。

## タスク 3 – AI アプリでの非倫理的な動作を検出する

このタスクでは、Microsoft 365 Copilot やその他の AI アプリケーションでの非倫理的または不適切な動作を検出するポリシーを、AI 用の DSPM に作成します。

1. Microsoft Purview で、**[ソリューション]** > **[AI 用 DSPM]** > **[推奨事項]** の順に選択して **[AI 用 DSPM]** に移動します。

1. **[AI アプリでの非倫理的な行為を検出する]** 推奨事項を選択します。

1. ポップアップで、このポリシーで構成される内容の概要を確認します。

   - 既定のポリシー名は、**AI 用 DSPM - AI アプリでの非倫理的な動作**です。

   - このポリシーは、Microsoft 365 Copilot やその他の AI エージェントのプロンプトと応答での機密情報または不適切な情報を検出します。

   - これは、組織内のすべてのユーザーとグループに適用されます。

1. **[ポリシーの作成]** を選択してコミュニケーション コンプライアンス ポリシーを作成します。

1. **[ポリシーが正常に作成されました]** ページで、**[X]** を選択してポップアップを閉じます。

1. **[推奨事項]** ページが更新され、**[AI アプリでの非倫理的な動作を検出する]** 推奨事項は **[完了]** に移動します。

1. 左側のナビゲーションで、 **[ポリシー]** を選択します。

1. 新しく作成した **AI 用 DSPM - AI アプリでの非倫理的な動作**ポリシーを選択して、その構成と状態を確認します。

1. **[AI 用 DSPM - AI アプリでの非倫理的な動作]** ページで、**[X]** を選択してポップアップを閉じます。

Contoso が Copilot の責任ある使用を維持するのに役立つ、AI アプリケーションでの非倫理的なアクティビティを検出するポリシーを作成しました。

## タスク 4: データ リスク評価を実行してラベルが設定されていないコンテンツを検出する

ラベル設定範囲の潜在的なギャップを把握するために、データ リスク評価を実行して、Copilot によってアクセスされる可能性のあるファイルで秘密度ラベルの無いものを特定します。

1. **[AI 用 DSPM]** で、**[Copilot およびエージェント応答で参照される機密データを保護する]** という推奨事項を選択します。

1. **[Copilot およびエージェント応答で参照される機密データを保護する]** ペインで概要を確認したあと、**[評価に移動]** を選択します。

1. **[データ リスク評価]** ページで、**[カスタム評価の作成 ]** を選択します。

1. **[基本情報]** ページで、次を入力します。

   - **名前**: `Unlabeled File Exposure Assessment`
   - **説明**: `Identifies files without sensitivity labels that may be exposed in Microsoft 365 Copilot responses and provides recommendations to reduce oversharing risks.`

1. [**次へ**] を選択します。

1. **[ユーザーの追加]** ページで、**[すべて]** を選択し、**[次へ]** を選択します。

1. **[評価するデータ ソースの追加]** ページで、既定の場所である **[SharePoint]** が選択されたままで **[次へ]** を選択します。

1. **[データ評価スキャンを確認して実行する]** ページで、**[保存して実行]** を選択します。

1. **[データ評価が正常に作成されました]** ページで、**[完了]** を選択します。

AI 用 Microsoft Purview DSPM を使用して、AI 関連のリスクを検出し、ポリシーを適用し、機密データの露出を評価できるようになって、組織が AI を安全に使用できるようになりました。
